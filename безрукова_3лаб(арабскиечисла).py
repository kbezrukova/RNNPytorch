# -*- coding: utf-8 -*-
"""Безрукова_3лаб(АрабскиеЧисла).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u0RiCXtEWK1sHr2cEB_CgdC_xzLFcvDt
"""

import os
import torch
import torch.nn as nn
from torch.utils.data import (
    Dataset,
    DataLoader,
)
import torchvision.transforms as transforms
import pandas as pd
from skimage import io
import matplotlib as mpl
import matplotlib.pyplot as plt
from tqdm import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class ArabicNumDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.annotations = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, index):
        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 1], self.annotations.iloc[index, 2])
        image = io.imread(img_path)
        y_label = torch.tensor(int(self.annotations.iloc[index, 0]))

        if self.transform:
            image = self.transform(image)

        return (image, y_label)

!unzip "/content/archive_arabic.zip"

import os
import pandas as pd
import cv2
from PIL import Image

list_ = []
for index, folder in enumerate(os.listdir("/content/dataset")):
    print(index, folder)
    for file in os.listdir(os.path.join("/content/dataset", str(folder))):
        basewidth = 32
        img = Image.open(os.path.join("/content/dataset/", str(folder), file))
        wpercent = (basewidth/float(img.size[0]))
        hsize = int((float(img.size[1])*float(wpercent)))
        img = img.resize((basewidth,hsize), Image.ANTIALIAS)
        img = img.convert('1')
        img.save(os.path.join("/content/dataset/", str(folder), file))
        im = cv2.imread(os.path.join("/content/dataset/", str(folder), file))
        print(im.shape)
        list_.extend([[index, folder, file]])

df = pd.DataFrame(list_)
df.to_csv("test1.csv",index=False)

dataset = ArabicNumDataset(
    csv_file="/content/test1.csv",
    root_dir="/content/dataset",
    transform=transforms.ToTensor(),
)

input_size = 32
hidden_size = 256
num_layers = 2
num_classes = 10
sequence_length = 32
learning_rate = 0.005
batch_size = 60
num_epochs = 100

train_set, test_set = torch.utils.data.random_split(dataset, [240, 60])
train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)

import matplotlib as mpl
import matplotlib.pyplot as plt
for i, (images, y_label) in enumerate(train_loader):
        print(images.size())
        image=images[0,:,:,:]
        image_s=torch.squeeze(image, 0)
        image_s=torch.squeeze(image_s, 0)
        image_s=image_s.T
        print(image_s.size())
        plt.imshow(image_s.numpy(), cmap="gray")
        break

class RNN(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes):
        super(RNN, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        out, _ = self.rnn(x, h0)
        out = out.reshape(out.shape[0], -1)
        out = self.fc(out)
        return out

model = RNN(input_size, hidden_size, num_layers, num_classes)
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
criterion = nn.CrossEntropyLoss()

for epoch in range(num_epochs):
    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):
        data = data.to(device=device).squeeze(1)
        targets = targets.to(device=device)
        scores = model(data)
        loss = criterion(scores, targets)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

def check_accuracy(loader, model):
    num_correct = 0
    num_samples = 0
    model.eval()
    with torch.no_grad():
        for x, y in loader:
            x = x.to(device=device).squeeze(1)
            y = y.to(device=device)
            scores = model(x)
            _, predictions = scores.max(1)
            num_correct += (predictions == y).sum()
            num_samples += predictions.size(0)
    model.train()
    return num_correct / num_samples
print(f"Accuracy on training set: {check_accuracy(train_loader, model)*100:2f}")
print(f"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}")